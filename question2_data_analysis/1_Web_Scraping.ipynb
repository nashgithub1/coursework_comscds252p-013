{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c156ce49-626e-4fff-ae8c-1563ac6b802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5649d3f-ddb8-4c81-921a-97ee8cc10740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "52bb101b-4c9f-4caa-84a5-bac20f0cb76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"http://books.toscrape.com/catalogue/page-{}.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8c47572-b1bc-48bf-be3a-965df271c9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url, retries=3):\n",
    "    for i in range(retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "            return BeautifulSoup(response.text, 'html.parser')\n",
    "        except Exception:\n",
    "            if i == retries - 1:\n",
    "                print(f\"Failed: {url}\")\n",
    "                return None\n",
    "            time.sleep(2)\n",
    "\n",
    "books_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e82f6095-2bae-440e-b397-27cded4f8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop to get books\n",
    "#get each book detail "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53027e96-e32e-4154-a5d2-f5dd1dc0fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looped through each book catalogue\n",
    "#because to get category for each book\n",
    "#took more time than usual\n",
    "\n",
    "for page in range(1, 6):\n",
    "    url = BASE_URL.format(page)\n",
    "    soup = get_soup(url)\n",
    "\n",
    "    if not soup:\n",
    "        continue\n",
    "\n",
    "    books = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "    for book in books:\n",
    "        try:\n",
    "            title = book.h3.a['title']\n",
    "            price = book.find('p', class_='price_color').text\n",
    "            rating = book.p['class'][1]\n",
    "            availability = book.find('p', class_='instock availability').text.strip()\n",
    "\n",
    "            #Get book detail page\n",
    "            book_url = book.h3.a['href']\n",
    "            book_url = \"http://books.toscrape.com/catalogue/\" + book_url\n",
    "\n",
    "            book_soup = get_soup(book_url)\n",
    "\n",
    "            category = \"Unknown\"\n",
    "            try:\n",
    "                breadcrumb = book_soup.find('ul', class_='breadcrumb')\n",
    "                category = breadcrumb.find_all('li')[2].text.strip()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            books_data.append([title, price, rating, availability, category])\n",
    "\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a166e3e7-1f4d-42db-8c0e-a88d968d75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "with open('books_uncleaned.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Title', 'Price', 'Rating', 'Availability', 'Category'])\n",
    "    writer.writerows(books_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
